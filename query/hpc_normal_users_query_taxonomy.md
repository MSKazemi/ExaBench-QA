
# ğŸ§  HPC Normal Users (Application Users / Scientists / Engineers)

## **Primary Mission**
- Efficiently run computational workloads and scientific simulations on HPC systems.
- Manage data, optimize performance, and ensure successful job execution.
- Utilize available HPC software environments for research and engineering tasks.

## **Core Tasks & Responsibilities**
- Submit, monitor, and manage batch or interactive jobs.
- Handle input/output datasets and organize project directories.
- Configure and load required software modules and environments.
- Debug failed jobs and analyze performance bottlenecks.
- Manage storage quotas and data transfers.
- Use GPUs and accelerators effectively for computation.
- Collaborate on shared HPC projects and manage access permissions.
- Follow documentation and tutorials to learn best practices.

## **Key Studies / Knowledge Areas**
- Linux shell and job schedulers (e.g., SLURM, PBS).
- Parallel programming concepts (MPI, OpenMP, CUDA).
- Scientific software stack and module systems.
- Data management on distributed file systems (Lustre, GPFS).
- Job profiling and performance tuning.
- GPU utilization and accelerator performance.
- Monitoring and interpreting HPC telemetry (CPU, memory, thermal, etc.).

## **Data Sources They Analyze**
- Job scheduler logs and accounting data.
- Output/error files from simulations.
- Monitoring telemetry (CPU, GPU, memory, temperature).
- Storage usage and quota statistics.
- SLURM and system status dashboards.

## **Tools & Frameworks**
- SLURM, PBS, or LSF job schedulers.
- HPC module system, Conda, virtualenv.
- JupyterHub, interactive shell tools.
- Prometheus/Grafana dashboards.
- File transfer tools (scp, rsync, Globus).
- Profiling tools (nvprof, perf, gprof).
- RAG Agent for documentation queries.
- ExaSage and Facility Agents for runtime and environmental monitoring.

## **Research Themes / Study Topics**
- Job execution and runtime optimization.
- Application scaling and parallel efficiency.
- Resource utilization and queue management.
- Workflow automation and scheduling policies.
- Energy-aware computing and sustainability.
- Debugging and reliability enhancement.
- Data management and reproducibility.
- User experience improvement via AI-driven assistants.

---

## **Example Queries for Multi-Agentic Chat System**

| # | Code | Category | Description | Example Queries | Priority |
|---|------|-----------|--------------|-----------------|-----------|
| 1 | **JOB** | **Job Submission & Management** | Submit, cancel, or resubmit jobs through schedulers. | â€œSubmit my script with 4 GPUs.â€<br>â€œCancel job 102345.â€ | **H** |
| 2 | **QUEUE** | **Queue & Resource Status** | View queues, waiting times, and node assignments. | â€œWhich queue has the shortest wait?â€<br>â€œShow my running jobs.â€ | **H** |
| 3 | **DATA** | **Data Management & File Operations** | Manage input/output data, clean directories, and perform transfers. | â€œCopy data to scratch.â€<br>â€œDelete old files older than 30 days.â€ | **H** |
| 4 | **SOFT** | **Software Modules & Environment Setup** | Load or configure scientific software environments. | â€œLoad Python 3.10 with TensorFlow.â€<br>â€œList available modules.â€ | **H** |
| 5 | **PERF** | **Performance Optimization** | Investigate runtime inefficiencies and recommend tuning actions. | â€œWhy is my job slow?â€<br>â€œShow CPU/GPU utilization for job 54321.â€ | **M** |
| 6 | **DEBUG** | **Troubleshooting & Debugging** | Diagnose job failures or software errors. | â€œWhy did my job fail?â€<br>â€œExplain MPI rank error.â€ | **H** |
| 7 | **GPU** | **GPU & Accelerator Usage** | Request or monitor GPU utilization and performance. | â€œRequest 2 GPUs for my next job.â€<br>â€œCheck GPU temperature.â€ | **M** |
| 8 | **STOR** | **Storage & Quota Management** | Manage storage usage and request additional quota. | â€œHow much storage am I using?â€<br>â€œList my largest files.â€ | **M** |
| 9 | **INTER** | **Interactive & Jupyter Workflows** | Launch interactive sessions or notebooks. | â€œLaunch Jupyter session.â€<br>â€œStart interactive job on GPU node.â€ | **M** |
| 10 | **DOCS** | **Documentation & Learning Assistance** | Retrieve examples, tutorials, and guidance. | â€œHow to use Python with MPI?â€<br>â€œFind example SLURM script.â€ | **H** |
| 11 | **COLL** | **Collaboration & Project Sharing** | Manage shared projects, permissions, and collaboration. | â€œShare folder with my project group.â€<br>â€œInvite collaborator to project.â€ | **M** |
| 12 | **MON** | **Monitoring & Runtime Metrics** | Query system or job metrics for analysis. | â€œShow CPU usage for my last job.â€<br>â€œPlot memory usage trend.â€ | **M** |
| 13 | **AUTO** | **Workflow Automation & Scripting** | Automate job submission or file-triggered workflows. | â€œSchedule daily job submission.â€<br>â€œTrigger workflow when dataset changes.â€ | **L** |
| 14 | **SEC** | **Security & Access Management** | Manage authentication and permissions. | â€œAdd my SSH key.â€<br>â€œReset my HPC password.â€ | **L** |
| 15 | **ENERGY** | **Facility Awareness & Energy Efficiency** | View sustainability and facility metrics. | â€œWhatâ€™s the PUE today?â€<br>â€œView cluster energy trends.â€ | **L** |

---

## **Priority Tags Summary**

| Priority | Meaning | Categories |
|----------|----------|------------|
| **H (High)** | Frequent, essential for daily workflow | JOB, QUEUE, DATA, SOFT, DEBUG, DOCS |
| **M (Medium)** | Regular but situational needs | PERF, GPU, STOR, INTER, COLL, MON |
| **L (Low)** | Occasional, admin-assisted, or advanced | AUTO, SEC, ENERGY |

---

<!-- Version: 1.0 â€” Generated 2025-10-31 -->
